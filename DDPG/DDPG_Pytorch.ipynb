{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "DDPG_Pytorch.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "_Tlbctonu3GW",
    "colab_type": "text"
   },
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "vtw6LhIBu3GX",
    "colab_type": "code",
    "outputId": "98778db1-f2e7-4c69-b3c5-4d65b9d41b5b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591351145657,
     "user_tz": -120,
     "elapsed": 8297,
     "user": {
      "displayName": "CLAUDIO CIAVOLA",
      "photoUrl": "https://lh3.googleusercontent.com/-KNU432Py9wA/AAAAAAAAAAI/AAAAAAAADvs/HFBxd4uSnlM/s64/photo.jpg",
      "userId": "08727435020611235754"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    }
   },
   "source": [
    "!pip install gym\n",
    "!pip install box2d_py"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (0.17.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym) (1.18.4)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n",
      "Collecting box2d_py\n",
      "\u001B[?25l  Downloading https://files.pythonhosted.org/packages/06/bd/6cdc3fd994b0649dcf5d9bad85bd9e26172308bbe9a421bfc6fdbf5081a6/box2d_py-2.3.8-cp36-cp36m-manylinux1_x86_64.whl (448kB)\n",
      "\u001B[K     |████████████████████████████████| 450kB 2.8MB/s \n",
      "\u001B[?25hInstalling collected packages: box2d-py\n",
      "Successfully installed box2d-py-2.3.8\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "z1VO12Rxu3Ga",
    "colab_type": "text"
   },
   "source": [
    "# Check if we are allocated a GPU\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "9Hae8b3Ju3Ga",
    "colab_type": "text"
   },
   "source": [
    "# Connect to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "EisctNHRu3Gb",
    "colab_type": "code",
    "outputId": "b913d8c8-04cc-4b95-8e04-ea6c387697cc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591351341442,
     "user_tz": -120,
     "elapsed": 204072,
     "user": {
      "displayName": "CLAUDIO CIAVOLA",
      "photoUrl": "https://lh3.googleusercontent.com/-KNU432Py9wA/AAAAAAAAAAI/AAAAAAAADvs/HFBxd4uSnlM/s64/photo.jpg",
      "userId": "08727435020611235754"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kgDQWE7cu3Gd",
    "colab_type": "code",
    "outputId": "ce93d9e1-650f-42ab-ee69-92031ec53a5e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591351342258,
     "user_tz": -120,
     "elapsed": 204877,
     "user": {
      "displayName": "CLAUDIO CIAVOLA",
      "photoUrl": "https://lh3.googleusercontent.com/-KNU432Py9wA/AAAAAAAAAAI/AAAAAAAADvs/HFBxd4uSnlM/s64/photo.jpg",
      "userId": "08727435020611235754"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "%cd /content/drive/My Drive/BipedalWalker-v3/DDPG"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1TyolH62paiFvrPtkZ3ZJunv4rqrxh7Nz/progettoDataDriven/gym_BipedalWalker-v3/DDPG/1_DDPG_Pytorch\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qcacxrfLu3Gg",
    "colab_type": "code",
    "outputId": "18caa65b-82f8-4f77-fc8d-ac8d371179a2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1591361855798,
     "user_tz": -120,
     "elapsed": 5108654,
     "user": {
      "displayName": "Claudio Ciavola",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjNrXmWiq435A7bf3y0NOFhGTLrKQGjt-wVcihJstw=s64",
      "userId": "14977292747668538818"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    }
   },
   "source": [
    "import gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from ddpg_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from collections import deque\n",
    "\n",
    "gym.logger.set_level(40)\n",
    "env = gym.make('BipedalWalker-v3')\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.shape[0]\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "MAX_EPISODES = 20000\n",
    "MAX_REWARD = 300\n",
    "MAX_STEPS = 2000  # env._max_episode_steps\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "GAMMA = 0.99  # discount factor\n",
    "TAU = 1e-3  # for soft update of target parameters\n",
    "LR = 5e-4  # learning rate\n",
    "UPDATE_EVERY = 4  # how often to update the network\n",
    "MEAN_EVERY = 100\n",
    "\n",
    "start_episode = 0\n",
    "\n",
    "agent = Agent(state_size=state_dim, action_size=action_dim, random_seed=0)\n",
    "\n",
    "LOAD = True\n",
    "noise = 1\n",
    "\n",
    "if LOAD:\n",
    "    start_episode = 18900\n",
    "    agent.actor_local.load_state_dict(torch.load('./actor/checkpoint_actor_ep18900.pth', map_location=\"cpu\"))\n",
    "    agent.critic_local.load_state_dict(torch.load('./critic/checkpoint_critic_ep18900.pth', map_location=\"cpu\"))\n",
    "    agent.actor_target.load_state_dict(torch.load('./actor/checkpoint_actor_t_ep18900.pth', map_location=\"cpu\"))\n",
    "    agent.critic_target.load_state_dict(torch.load('./critic/checkpoint_critic_t_ep18900.pth', map_location=\"cpu\"))\n",
    "\n",
    "scores = []\n",
    "mean_scores = []\n",
    "last_scores = deque(maxlen=MEAN_EVERY)\n",
    "distances = []\n",
    "mean_distances = []\n",
    "last_distance = deque(maxlen=MEAN_EVERY)\n",
    "losses_mean_episode = []\n",
    "\n",
    "for ep in range(start_episode + 1, MAX_EPISODES + 1):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    total_distance = 0\n",
    "    actor_losses = []\n",
    "    critic_losses = []\n",
    "    for t in range(MAX_STEPS):\n",
    "\n",
    "        # env.render()\n",
    "\n",
    "        action = agent.act(state, noise)\n",
    "        next_state, reward, done, info = env.step(action[0])\n",
    "        next_state = next_state\n",
    "        actor_loss, critic_loss = agent.step(state, action, reward, next_state, done)\n",
    "        if actor_loss is not None:\n",
    "            actor_losses.append(actor_loss)\n",
    "        if critic_loss is not None:\n",
    "            critic_losses.append(critic_loss)\n",
    "        state = next_state.squeeze()\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        if reward != -100:\n",
    "            total_distance += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if len(actor_losses) >= 1 and len(critic_losses) >= 1:\n",
    "        mean_loss_actor = np.mean(actor_losses)\n",
    "        mean_loss_critic = np.mean(critic_losses)\n",
    "        losses_mean_episode.append((ep, mean_loss_actor, mean_loss_critic))\n",
    "    else:\n",
    "        mean_loss_actor = None\n",
    "        mean_loss_critic = None\n",
    "\n",
    "    print(\n",
    "        '\\rEpisode: {}/{},\\tScore: {:.2f},\\tDistance: {:.2f},\\tactor_loss: {},\\tcritic_loss:{}'.format(ep, MAX_EPISODES,\n",
    "                                                                                                       total_reward,\n",
    "                                                                                                       total_distance,\n",
    "                                                                                                       mean_loss_actor,\n",
    "                                                                                                       mean_loss_critic),\n",
    "        end=\"\")\n",
    "\n",
    "    scores.append(total_reward)\n",
    "    distances.append(total_distance)\n",
    "    last_scores.append(total_reward)\n",
    "    last_distance.append(total_distance)\n",
    "    mean_score = np.mean(last_scores)\n",
    "    mean_distance = np.mean(last_distance)\n",
    "    FILE = 'record.dat'\n",
    "    data = [ep, total_reward, total_distance, mean_loss_actor, mean_loss_critic]\n",
    "    with open(FILE, \"ab\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "    if mean_score >= 300:\n",
    "        print('Task Solved')\n",
    "        torch.save(agent.actor_local.state_dict(), './actor/checkpoint_actor_best_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), './critic/checkpoint_critic_best_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.actor_target.state_dict(), './actor/checkpoint_actor_best_t_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.critic_target.state_dict(), './critic/checkpoint_critic_best_t_ep' + str(ep) + '.pth')\n",
    "        break\n",
    "\n",
    "    if ((ep % MEAN_EVERY) == 0):\n",
    "        torch.save(agent.actor_local.state_dict(), './actor/checkpoint_actor_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), './critic/checkpoint_critic_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.actor_target.state_dict(), './actor/checkpoint_actor_t_ep' + str(ep) + '.pth')\n",
    "        torch.save(agent.critic_target.state_dict(), './critic/checkpoint_critic_t_ep' + str(ep) + '.pth')\n",
    "        mean_scores.append(mean_score)\n",
    "        mean_distances.append(mean_distance)\n",
    "        print('\\rEpisode: {}/{},\\tMean Score: {:.2f},\\tMean Distance: {:.2f},\\tactor_loss: {},\\tcritic_loss:{}'.format(\n",
    "            ep, MAX_EPISODES,\n",
    "            mean_score,\n",
    "            mean_distance, mean_loss_actor,\n",
    "            mean_loss_critic))\n",
    "        FILE = 'record_mean.dat'\n",
    "        data = [ep, mean_score, mean_distance, mean_loss_actor, mean_loss_critic]\n",
    "        with open(FILE, \"ab\") as f:\n",
    "            pickle.dump(data, f)\n",
    "env.close()\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Episode: 19000/20000,\tMean Score: -109.16,\tMean Distance: -9.16,\tactor_loss: 1.3522928953170776,\tcritic_loss:3.7594549655914307\n",
      "Episode: 19100/20000,\tMean Score: -109.09,\tMean Distance: -9.09,\tactor_loss: 3.221298933029175,\tcritic_loss:3.918891668319702\n",
      "Episode: 19200/20000,\tMean Score: -105.06,\tMean Distance: -5.06,\tactor_loss: 3.8261525630950928,\tcritic_loss:3.7365567684173584\n",
      "Episode: 19300/20000,\tMean Score: -104.06,\tMean Distance: -4.06,\tactor_loss: 2.9740633964538574,\tcritic_loss:3.3186819553375244\n",
      "Episode: 19400/20000,\tMean Score: -100.50,\tMean Distance: -0.50,\tactor_loss: 2.3565618991851807,\tcritic_loss:3.8741800785064697\n",
      "Episode: 19500/20000,\tMean Score: -101.83,\tMean Distance: -1.83,\tactor_loss: 1.7265989780426025,\tcritic_loss:4.448746681213379\n",
      "Episode: 19600/20000,\tMean Score: -106.94,\tMean Distance: -6.94,\tactor_loss: 0.46157369017601013,\tcritic_loss:4.289445400238037\n",
      "Episode: 19700/20000,\tMean Score: -107.16,\tMean Distance: -8.16,\tactor_loss: 0.7497286796569824,\tcritic_loss:4.926478385925293\n",
      "Episode: 19800/20000,\tMean Score: -103.63,\tMean Distance: -3.63,\tactor_loss: 2.606708288192749,\tcritic_loss:4.666821479797363\n",
      "Episode: 19900/20000,\tMean Score: -104.83,\tMean Distance: -4.83,\tactor_loss: 3.1976640224456787,\tcritic_loss:5.452121734619141\n",
      "Episode: 20000/20000,\tMean Score: -102.25,\tMean Distance: -2.25,\tactor_loss: 5.160646438598633,\tcritic_loss:5.2876763343811035\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}